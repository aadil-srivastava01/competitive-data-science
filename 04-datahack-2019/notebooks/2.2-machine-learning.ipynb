{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import copy\n",
    "#from tqdm import tqdm, tqdm_notebook, trange\n",
    "from scipy.optimize import fmin\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#import lightgbm as lgbm\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, log_loss, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#from eli5.permutation_importance import get_score_importances\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTestHelper(object):\n",
    "    def __init__(self):\n",
    "        self.ntrain = None\n",
    "\n",
    "    def combine(self, train, test):\n",
    "        self.ntrain = train.shape[0]\n",
    "        if isinstance(train, np.ndarray):\n",
    "            return np.row_stack((train, test))\n",
    "        else:\n",
    "            return train.append(test).reset_index(drop=True)\n",
    "\n",
    "    def split(self, train_test):\n",
    "        if self.ntrain is None:\n",
    "            return None\n",
    "        if isinstance(train_test, np.ndarray):\n",
    "            train = train_test[:self.ntrain, :]\n",
    "            test = train_test[self.ntrain:, :]\n",
    "        else:\n",
    "            train = train_test.iloc[:self.ntrain, :].copy().reset_index(drop=True)\n",
    "            test = train_test.iloc[self.ntrain:, :].copy().reset_index(drop=True)\n",
    "        return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataDivision(object):\n",
    "    \"\"\"\n",
    "    this is a helper class that divides the data into trainset and validset and vice versa\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.xshape = None\n",
    "        \n",
    "    def concat(self, train, valid):\n",
    "        \"\"\"\n",
    "        this module combines the already divided trainset and validset into one whole dataset \n",
    "        \"\"\"\n",
    "        self.xshape = train.shape[0]  # len of the trainset\n",
    "        \n",
    "        # below logic checks whether train is numpy instance or pandas instance and deals with it accordingly\n",
    "        if isinstance(train, np.ndarray):\n",
    "            return np.row_stack((train, valid))\n",
    "        else:\n",
    "            return train.append(valid).reset_index(drop = True)\n",
    "        \n",
    "    def split(self, train_test):\n",
    "        if self.xshape is None:\n",
    "            return None\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
