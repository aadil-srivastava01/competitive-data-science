{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc, warnings, random, math\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17\n",
    "TARGET = 'meter_reading'\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('df_train.pkl')\n",
    "df_test = pd.read_pickle('df_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df_train['primary_use'] = df_train['primary_use'].astype(str)\n",
    "df_train['primary_use'] = le.fit_transform(df_train['primary_use']).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train, df_test]:\n",
    "    \n",
    "    df['DT_D'] = df['timestamp'].dt.dayofyear.astype(np.int16)\n",
    "    df['DT_M'] = df['timestamp'].dt.month.astype(np.int8)\n",
    "    df['DT_hour'] = df['timestamp'].dt.hour.astype(np.int8)\n",
    "    df[\"weekday\"] = df['timestamp'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>DT_D</th>\n",
       "      <th>DT_M</th>\n",
       "      <th>DT_hour</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2720</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5376</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23685</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116607</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter  timestamp  meter_reading  site_id  primary_use  \\\n",
       "0            0      0 2016-01-01            0.0        0            0   \n",
       "1            1      0 2016-01-01            0.0        0            0   \n",
       "2            2      0 2016-01-01            0.0        0            0   \n",
       "3            3      0 2016-01-01            0.0        0            0   \n",
       "4            4      0 2016-01-01            0.0        0            0   \n",
       "\n",
       "   square_feet  year_built  floor_count  air_temperature  cloud_coverage  \\\n",
       "0         7432      2008.0          NaN             25.0             6.0   \n",
       "1         2720      2004.0          NaN             25.0             6.0   \n",
       "2         5376      1991.0          NaN             25.0             6.0   \n",
       "3        23685      2002.0          NaN             25.0             6.0   \n",
       "4       116607      1975.0          NaN             25.0             6.0   \n",
       "\n",
       "   dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_direction  \\\n",
       "0             20.0                NaN              1019.5             0.0   \n",
       "1             20.0                NaN              1019.5             0.0   \n",
       "2             20.0                NaN              1019.5             0.0   \n",
       "3             20.0                NaN              1019.5             0.0   \n",
       "4             20.0                NaN              1019.5             0.0   \n",
       "\n",
       "   wind_speed  DT_D  DT_M  DT_hour  weekday  \n",
       "0         0.0     1     1        0        4  \n",
       "1         0.0     1     1        0        4  \n",
       "2         0.0     1     1        0        4  \n",
       "3         0.0     1     1        0        4  \n",
       "4         0.0     1     1        0        4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Buildings are exclusive in test set\n",
      "0: Sites are exclusive in test set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df_test[~df_test['building_id'].isin(df_train['building_id'])]\n",
    "print(f\"{len(temp)}: Buildings are exclusive in test set\")\n",
    "temp = df_test[~df_test['site_id'].isin(df_train['site_id'])]\n",
    "print(f\"{len(temp)}: Sites are exclusive in test set\")\n",
    "del temp, df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Holdout sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11100638, 20)\n",
      "(6093592, 20)\n",
      "(3021870, 20)\n",
      "(1886471, 20)\n"
     ]
    }
   ],
   "source": [
    "#1st Holdout set\n",
    "# Split the train set by site_id -> ~20% in the validation set\n",
    "train,test = train_test_split(df_train['site_id'].unique(), test_size=0.2, random_state=SEED)\n",
    "holdout_set1 = df_train[df_train['site_id'].isin(test)].reset_index(drop=True)\n",
    "df_train = df_train[df_train['site_id'].isin(train)].reset_index(drop=True)\n",
    "\n",
    "#2nd Holdout set\n",
    "#Split the train set by building_id -> ~20% in the validation set\n",
    "train,test = train_test_split(df_train['building_id'].unique(), test_size=0.2, random_state=SEED)\n",
    "holdout_set2 = df_train[df_train['building_id'].isin(test)].reset_index(drop=True)\n",
    "df_train = df_train[df_train['building_id'].isin(train)].reset_index(drop=True)\n",
    "\n",
    "#3rd Holdout set\n",
    "#Split the train set by month -> First and Last Month in holdout set\n",
    "holdout_set3 = df_train[(df_train['DT_M']==1) | (df_train['DT_M'] ==12)].reset_index(drop=True)\n",
    "df_train = df_train[(df_train['DT_M']!=1) & (df_train['DT_M']) !=12].reset_index(drop=True)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "for df in [df_train, holdout_set1, holdout_set2, holdout_set3]:\n",
    "    df['meter_reading'] = np.log1p(df['meter_reading'])\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_columns = ['timestamp', 'site_id', 'building_id', TARGET]\n",
    "features_columns = [col for col in list(df_train) if col not in remove_columns]\n",
    "\n",
    "X = df_train[features_columns]\n",
    "y = df_train[TARGET]\n",
    "\n",
    "split_by_building = df_train['building_id']\n",
    "split_by_site = df_train['site_id']\n",
    "split_by_month = df_train['DT_M']\n",
    "\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "READING_1 = holdout_set1[[TARGET]]\n",
    "READING_2 = holdout_set2[[TARGET]]\n",
    "READING_3 = holdout_set3[[TARGET]]\n",
    "\n",
    "all_readings = {\n",
    "    1:[READING_1, holdout_set1, 'site_id_hold_out'],\n",
    "    2:[READING_2, holdout_set2, 'build_id_hold_out'],\n",
    "    3:[READING_3, holdout_set3, 'month_hold_out']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground RMSE for site_id_hold_out | 4.079004001648642\n",
      "##################################################\n",
      "Ground RMSE for build_id_hold_out | 4.852578694256156\n",
      "##################################################\n",
      "Ground RMSE for month_hold_out | 4.891736616059323\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "for _,df in all_readings.items():\n",
    "    df[0]['test'] = 0    \n",
    "    print('Ground RMSE for', df[2], '|',\n",
    "          rmse(df[0][TARGET], df[0]['test']))\n",
    "    del df[0]['test']\n",
    "    print('#'*50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WE will be using same number of splits for traning the model\n",
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "                    'objective':'regression',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'rmse',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.3, #for faster training\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':1000,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "No Validation training... 25 boosting rounds\n",
      "RMSE for site_id_hold_out | 1.8034363811658465\n",
      "####################\n",
      "RMSE for build_id_hold_out | 1.8356204160147487\n",
      "####################\n",
      "RMSE for month_hold_out | 1.019487394171583\n",
      "####################\n",
      "##################################################\n",
      "No Validation training... 50 boosting rounds\n",
      "RMSE for site_id_hold_out | 1.8214261174575703\n",
      "####################\n",
      "RMSE for build_id_hold_out | 1.8588791429308105\n",
      "####################\n",
      "RMSE for month_hold_out | 0.9110584084338825\n",
      "####################\n",
      "##################################################\n",
      "No Validation training... 100 boosting rounds\n",
      "RMSE for site_id_hold_out | 1.847634791180678\n",
      "####################\n",
      "RMSE for build_id_hold_out | 1.9018452064427318\n",
      "####################\n",
      "RMSE for month_hold_out | 0.7692495781105358\n",
      "####################\n",
      "##################################################\n",
      "No Validation training... 200 boosting rounds\n",
      "RMSE for site_id_hold_out | 1.8634686313580016\n",
      "####################\n",
      "RMSE for build_id_hold_out | 1.9253166416393728\n",
      "####################\n",
      "RMSE for month_hold_out | 0.6721322162429606\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "#Trying Multiple bossting round to find the best among them\n",
    "for n_rounds in [25,50,100,200]:\n",
    "    \n",
    "    print('#'*50)\n",
    "    print('No Validation training...', n_rounds, 'boosting rounds')\n",
    "    corrected_lgb_params = params.copy()\n",
    "    corrected_lgb_params['n_estimators'] = n_rounds\n",
    "    corrected_lgb_params['early_stopping_rounds'] = None\n",
    "\n",
    "    train_data = lgb.Dataset(X, label=y)\n",
    "    \n",
    "    estimator = lgb.train(\n",
    "                corrected_lgb_params,\n",
    "                train_data\n",
    "            )\n",
    "    gc.collect()\n",
    "    for _,df in all_readings.items():\n",
    "        df[0]['no_validation_'+str(n_rounds)] = estimator.predict(df[1][features_columns])\n",
    "        print('RMSE for',\n",
    "              df[2], '|',\n",
    "              rmse(df[0][TARGET], df[0]['no_validation_'+str(n_rounds)]))\n",
    "        print('#'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Results suggest there is data leakage by in our dataset__ \n",
    "* leakage by Site_ID ->> Model Performs poorly on unknown sites hence doesn't generalize well \n",
    "* leakage by Building_IX ->> Model Performs poorly on unknown buildings hence doesn't generalize well \n",
    "\n",
    "Luckily our train set has same site and building ids as that of test set. Probably we don't need to smooth differences between them and can even make differences more explicit.\n",
    "So, a good CV set should have all buildings and site information as bulidings and sites have very unqiue energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "KFold (with shuffle) training...\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.840837\tvalid_1's rmse: 0.847049\n",
      "[200]\ttraining's rmse: 0.740143\tvalid_1's rmse: 0.752516\n",
      "[300]\ttraining's rmse: 0.691265\tvalid_1's rmse: 0.709239\n",
      "[400]\ttraining's rmse: 0.661194\tvalid_1's rmse: 0.684618\n",
      "[500]\ttraining's rmse: 0.641667\tvalid_1's rmse: 0.67071\n",
      "[600]\ttraining's rmse: 0.626189\tvalid_1's rmse: 0.660287\n",
      "[700]\ttraining's rmse: 0.612522\tvalid_1's rmse: 0.651362\n",
      "[800]\ttraining's rmse: 0.600321\tvalid_1's rmse: 0.643619\n",
      "[900]\ttraining's rmse: 0.591052\tvalid_1's rmse: 0.638665\n",
      "[1000]\ttraining's rmse: 0.581723\tvalid_1's rmse: 0.633969\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.581723\tvalid_1's rmse: 0.633969\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.839413\tvalid_1's rmse: 0.844919\n",
      "[200]\ttraining's rmse: 0.76023\tvalid_1's rmse: 0.771301\n",
      "[300]\ttraining's rmse: 0.711177\tvalid_1's rmse: 0.727969\n",
      "[400]\ttraining's rmse: 0.680557\tvalid_1's rmse: 0.703053\n",
      "[500]\ttraining's rmse: 0.65702\tvalid_1's rmse: 0.684683\n",
      "[600]\ttraining's rmse: 0.639095\tvalid_1's rmse: 0.671546\n",
      "[700]\ttraining's rmse: 0.623344\tvalid_1's rmse: 0.660591\n",
      "[800]\ttraining's rmse: 0.60754\tvalid_1's rmse: 0.649865\n",
      "[900]\ttraining's rmse: 0.596606\tvalid_1's rmse: 0.643288\n",
      "[1000]\ttraining's rmse: 0.586631\tvalid_1's rmse: 0.637537\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.586631\tvalid_1's rmse: 0.637537\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.842136\tvalid_1's rmse: 0.848468\n",
      "[200]\ttraining's rmse: 0.754531\tvalid_1's rmse: 0.766791\n",
      "[300]\ttraining's rmse: 0.707162\tvalid_1's rmse: 0.725546\n",
      "[400]\ttraining's rmse: 0.677845\tvalid_1's rmse: 0.702332\n",
      "[500]\ttraining's rmse: 0.657184\tvalid_1's rmse: 0.687272\n",
      "[600]\ttraining's rmse: 0.640158\tvalid_1's rmse: 0.675541\n",
      "[700]\ttraining's rmse: 0.625084\tvalid_1's rmse: 0.665618\n",
      "[800]\ttraining's rmse: 0.611785\tvalid_1's rmse: 0.657403\n",
      "[900]\ttraining's rmse: 0.60117\tvalid_1's rmse: 0.65134\n",
      "[1000]\ttraining's rmse: 0.59194\tvalid_1's rmse: 0.646641\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.59194\tvalid_1's rmse: 0.646641\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.848085\tvalid_1's rmse: 0.853848\n",
      "[200]\ttraining's rmse: 0.751074\tvalid_1's rmse: 0.763727\n",
      "[300]\ttraining's rmse: 0.698598\tvalid_1's rmse: 0.717459\n",
      "[400]\ttraining's rmse: 0.67059\tvalid_1's rmse: 0.69511\n",
      "[500]\ttraining's rmse: 0.648013\tvalid_1's rmse: 0.678303\n",
      "[600]\ttraining's rmse: 0.630624\tvalid_1's rmse: 0.665881\n",
      "[700]\ttraining's rmse: 0.616163\tvalid_1's rmse: 0.656324\n",
      "[800]\ttraining's rmse: 0.60407\tvalid_1's rmse: 0.648868\n",
      "[900]\ttraining's rmse: 0.594373\tvalid_1's rmse: 0.64318\n",
      "[1000]\ttraining's rmse: 0.584092\tvalid_1's rmse: 0.637304\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.584092\tvalid_1's rmse: 0.637304\n",
      "Fold: 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.848969\tvalid_1's rmse: 0.855436\n",
      "[200]\ttraining's rmse: 0.743467\tvalid_1's rmse: 0.755808\n",
      "[300]\ttraining's rmse: 0.697972\tvalid_1's rmse: 0.716231\n",
      "[400]\ttraining's rmse: 0.668551\tvalid_1's rmse: 0.692579\n",
      "[500]\ttraining's rmse: 0.647079\tvalid_1's rmse: 0.676806\n",
      "[600]\ttraining's rmse: 0.627341\tvalid_1's rmse: 0.662548\n",
      "[700]\ttraining's rmse: 0.610627\tvalid_1's rmse: 0.650673\n",
      "[800]\ttraining's rmse: 0.598331\tvalid_1's rmse: 0.643398\n",
      "[900]\ttraining's rmse: 0.589033\tvalid_1's rmse: 0.638258\n",
      "[1000]\ttraining's rmse: 0.578416\tvalid_1's rmse: 0.631889\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.578416\tvalid_1's rmse: 0.631889\n",
      "RMSE for site_id_hold_out | 1.8358450989975514\n",
      "####################\n",
      "RMSE for build_id_hold_out | 1.9072805499188739\n",
      "####################\n",
      "RMSE for month_hold_out | 0.48456399374202314\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "print('#'*20)\n",
    "print('KFold (with shuffle) training...')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "folds = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for _,df in all_readings.items():\n",
    "    df[0]['shuffle_kfold'] = 0\n",
    "        \n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    print('Fold:',fold_+1)\n",
    "    tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]    \n",
    "    vl_x, v_y = X.iloc[val_idx,:], y[val_idx]    \n",
    "    train_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    valid_data = lgb.Dataset(vl_x, label=v_y)  \n",
    "\n",
    "    estimator = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets = [train_data, valid_data],\n",
    "            verbose_eval = 100,\n",
    "        )\n",
    "    \n",
    "    for _,df in all_readings.items():\n",
    "        df[0]['shuffle_kfold'] += estimator.predict(df[1][features_columns])/N_SPLITS\n",
    "\n",
    "for _,df in all_readings.items():\n",
    "    print('RMSE for', df[2], '|',\n",
    "          rmse(df[0][TARGET], df[0]['shuffle_kfold']))\n",
    "    print('#'*20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note: Changing the number of splits 5 to 3, as it is taking quite a bit of time, but will use 5-Fold for the traning the final model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "KFold (no shuffle) training...\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.822771\tvalid_1's rmse: 1.14989\n",
      "[200]\ttraining's rmse: 0.733507\tvalid_1's rmse: 1.11497\n",
      "[300]\ttraining's rmse: 0.685091\tvalid_1's rmse: 1.10126\n",
      "[400]\ttraining's rmse: 0.657216\tvalid_1's rmse: 1.09781\n",
      "[500]\ttraining's rmse: 0.636075\tvalid_1's rmse: 1.09798\n",
      "Early stopping, best iteration is:\n",
      "[413]\ttraining's rmse: 0.653841\tvalid_1's rmse: 1.09713\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.819684\tvalid_1's rmse: 1.29443\n",
      "[200]\ttraining's rmse: 0.729502\tvalid_1's rmse: 1.27238\n",
      "[300]\ttraining's rmse: 0.677533\tvalid_1's rmse: 1.26768\n",
      "[400]\ttraining's rmse: 0.649741\tvalid_1's rmse: 1.26828\n",
      "Early stopping, best iteration is:\n",
      "[302]\ttraining's rmse: 0.677133\tvalid_1's rmse: 1.26754\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.850857\tvalid_1's rmse: 1.18341\n",
      "[200]\ttraining's rmse: 0.734711\tvalid_1's rmse: 1.1478\n",
      "[300]\ttraining's rmse: 0.680205\tvalid_1's rmse: 1.13287\n",
      "[400]\ttraining's rmse: 0.649327\tvalid_1's rmse: 1.12489\n",
      "[500]\ttraining's rmse: 0.629514\tvalid_1's rmse: 1.12503\n",
      "Early stopping, best iteration is:\n",
      "[450]\ttraining's rmse: 0.638611\tvalid_1's rmse: 1.12295\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.818421\tvalid_1's rmse: 1.25225\n",
      "[200]\ttraining's rmse: 0.724157\tvalid_1's rmse: 1.23222\n",
      "[300]\ttraining's rmse: 0.672441\tvalid_1's rmse: 1.22404\n",
      "[400]\ttraining's rmse: 0.64682\tvalid_1's rmse: 1.22121\n",
      "[500]\ttraining's rmse: 0.625134\tvalid_1's rmse: 1.22013\n",
      "Early stopping, best iteration is:\n",
      "[475]\ttraining's rmse: 0.628684\tvalid_1's rmse: 1.2192\n",
      "Fold: 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.823069\tvalid_1's rmse: 1.34586\n",
      "[200]\ttraining's rmse: 0.739701\tvalid_1's rmse: 1.35729\n",
      "Early stopping, best iteration is:\n",
      "[100]\ttraining's rmse: 0.823069\tvalid_1's rmse: 1.34586\n",
      "RMSE for site_id_hold_out | 1.7382660011065507\n",
      "####################\n",
      "RMSE for build_id_hold_out | 1.8660018845918092\n",
      "####################\n",
      "RMSE for month_hold_out | 0.6291536681196875\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "print('#'*20)\n",
    "print('KFold (no shuffle) training...')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "folds = KFold(n_splits=N_SPLITS, shuffle=False, random_state=SEED)\n",
    "\n",
    "for _,df in all_readings.items():\n",
    "    df[0]['no_shuffle_kfold'] = 0\n",
    "        \n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    print('Fold:',fold_+1)\n",
    "    tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]    \n",
    "    vl_x, v_y = X.iloc[val_idx,:], y[val_idx]    \n",
    "    train_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    valid_data = lgb.Dataset(vl_x, label=v_y)  \n",
    "\n",
    "    estimator = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets = [train_data, valid_data],\n",
    "            verbose_eval = 100,\n",
    "        )\n",
    "    \n",
    "    for _,df in all_readings.items():\n",
    "        df[0]['no_shuffle_kfold'] += estimator.predict(df[1][features_columns])/N_SPLITS\n",
    "\n",
    "for _,df in all_readings.items():\n",
    "    print('RMSE for', df[2], '|',\n",
    "          rmse(df[0][TARGET], df[0]['no_shuffle_kfold']))\n",
    "    print('#'*20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note: Data Leakage by month: Consumption differ from month to month on a quite significant magnitude, hence we cannot exclude any data by month.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "GroupKFold site_id split training...\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.689716\tvalid_1's rmse: 2.46855\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's rmse: 1.50392\tvalid_1's rmse: 2.21927\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.76513\tvalid_1's rmse: 2.45799\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's rmse: 1.35218\tvalid_1's rmse: 2.34451\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.818165\tvalid_1's rmse: 2.01695\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's rmse: 1.95204\tvalid_1's rmse: 1.59192\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.871039\tvalid_1's rmse: 2.18259\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 2.11216\tvalid_1's rmse: 1.8382\n",
      "Fold: 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.812687\tvalid_1's rmse: 2.60449\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's rmse: 1.35243\tvalid_1's rmse: 2.52278\n",
      "RMSE for site_id_hold_out | 1.6241344029140803\n",
      "####################\n",
      "RMSE for build_id_hold_out | 1.9341676092577051\n",
      "####################\n",
      "RMSE for month_hold_out | 1.7388784491855611\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "print('#'*20)\n",
    "print('GroupKFold site_id split training...') \n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "folds = GroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "for _,df in all_readings.items():\n",
    "    df[0]['Groupkfold_by_site'] = 0\n",
    "      \n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups=split_by_site)):\n",
    "    print('Fold:',fold_+1)\n",
    "    tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]    \n",
    "    vl_x, v_y = X.iloc[val_idx,:], y[val_idx]    \n",
    "    train_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    valid_data = lgb.Dataset(vl_x, label=v_y)  \n",
    "\n",
    "    estimator = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets = [train_data, valid_data],\n",
    "            verbose_eval = 100,\n",
    "        )\n",
    "\n",
    "    for _,df in all_readings.items():\n",
    "        df[0]['Groupkfold_by_site'] += estimator.predict(df[1][features_columns])/N_SPLITS\n",
    "\n",
    "for _,df in all_readings.items():\n",
    "    print('RMSE for', df[2], '|',\n",
    "          rmse(df[0][TARGET], df[0]['Groupkfold_by_site']))\n",
    "    print('#'*20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "GroupKFold building_id split training...\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.793632\tvalid_1's rmse: 1.97884\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's rmse: 1.28488\tvalid_1's rmse: 1.89974\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.799639\tvalid_1's rmse: 2.01162\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's rmse: 1.08446\tvalid_1's rmse: 1.96904\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.794838\tvalid_1's rmse: 1.93188\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's rmse: 1.39585\tvalid_1's rmse: 1.8236\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.78317\tvalid_1's rmse: 1.93792\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's rmse: 1.09354\tvalid_1's rmse: 1.84784\n",
      "Fold: 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.803491\tvalid_1's rmse: 1.88542\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's rmse: 1.11704\tvalid_1's rmse: 1.80732\n",
      "RMSE for site_id_hold_out | 1.673026798791022\n",
      "####################\n",
      "RMSE for build_id_hold_out | 1.731749140551592\n",
      "####################\n",
      "RMSE for month_hold_out | 1.185985648923007\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "print('#'*20)\n",
    "print('GroupKFold building_id split training...') \n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "folds = GroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "for _,df in all_readings.items():\n",
    "    df[0]['Groupkfold_by_building'] = 0\n",
    "      \n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups=split_by_building)):\n",
    "    print('Fold:',fold_+1)\n",
    "    tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]    \n",
    "    vl_x, v_y = X.iloc[val_idx,:], y[val_idx]    \n",
    "    train_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    valid_data = lgb.Dataset(vl_x, label=v_y)  \n",
    "\n",
    "    estimator = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets = [train_data, valid_data],\n",
    "            verbose_eval = 100,\n",
    "        )\n",
    "\n",
    "    for _,df in all_readings.items():\n",
    "        df[0]['Groupkfold_by_building'] += estimator.predict(df[1][features_columns])/N_SPLITS\n",
    "\n",
    "for _,df in all_readings.items():\n",
    "    print('RMSE for', df[2], '|',\n",
    "          rmse(df[0][TARGET], df[0]['Groupkfold_by_building']))\n",
    "    print('#'*20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "GroupKFold month split training...\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.82462\tvalid_1's rmse: 1.19126\n",
      "[200]\ttraining's rmse: 0.724895\tvalid_1's rmse: 1.14063\n",
      "[300]\ttraining's rmse: 0.68016\tvalid_1's rmse: 1.12515\n",
      "[400]\ttraining's rmse: 0.653834\tvalid_1's rmse: 1.1187\n",
      "[500]\ttraining's rmse: 0.632643\tvalid_1's rmse: 1.11052\n",
      "[600]\ttraining's rmse: 0.615497\tvalid_1's rmse: 1.10501\n",
      "[700]\ttraining's rmse: 0.600371\tvalid_1's rmse: 1.10254\n",
      "[800]\ttraining's rmse: 0.586894\tvalid_1's rmse: 1.10002\n",
      "[900]\ttraining's rmse: 0.577362\tvalid_1's rmse: 1.09844\n",
      "[1000]\ttraining's rmse: 0.565809\tvalid_1's rmse: 1.09642\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.565809\tvalid_1's rmse: 1.09642\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.815783\tvalid_1's rmse: 1.19848\n",
      "[200]\ttraining's rmse: 0.737851\tvalid_1's rmse: 1.17847\n",
      "[300]\ttraining's rmse: 0.686556\tvalid_1's rmse: 1.17025\n",
      "[400]\ttraining's rmse: 0.658957\tvalid_1's rmse: 1.16498\n",
      "[500]\ttraining's rmse: 0.637964\tvalid_1's rmse: 1.16484\n",
      "Early stopping, best iteration is:\n",
      "[414]\ttraining's rmse: 0.654421\tvalid_1's rmse: 1.1644\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.840317\tvalid_1's rmse: 1.12282\n",
      "[200]\ttraining's rmse: 0.747742\tvalid_1's rmse: 1.09617\n",
      "[300]\ttraining's rmse: 0.699332\tvalid_1's rmse: 1.07918\n",
      "[400]\ttraining's rmse: 0.661046\tvalid_1's rmse: 1.06896\n",
      "Early stopping, best iteration is:\n",
      "[385]\ttraining's rmse: 0.663859\tvalid_1's rmse: 1.06524\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.824032\tvalid_1's rmse: 1.08169\n",
      "[200]\ttraining's rmse: 0.74417\tvalid_1's rmse: 1.06251\n",
      "[300]\ttraining's rmse: 0.700646\tvalid_1's rmse: 1.05805\n",
      "[400]\ttraining's rmse: 0.668391\tvalid_1's rmse: 1.05849\n",
      "Early stopping, best iteration is:\n",
      "[309]\ttraining's rmse: 0.697176\tvalid_1's rmse: 1.05715\n",
      "Fold: 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.827008\tvalid_1's rmse: 1.08126\n",
      "[200]\ttraining's rmse: 0.7291\tvalid_1's rmse: 1.0552\n",
      "[300]\ttraining's rmse: 0.68312\tvalid_1's rmse: 1.04859\n",
      "[400]\ttraining's rmse: 0.652875\tvalid_1's rmse: 1.04542\n",
      "[500]\ttraining's rmse: 0.630106\tvalid_1's rmse: 1.04364\n",
      "[600]\ttraining's rmse: 0.611268\tvalid_1's rmse: 1.04208\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttraining's rmse: 0.612551\tvalid_1's rmse: 1.04196\n",
      "RMSE for site_id_hold_out | 1.8098096390528202\n",
      "####################\n",
      "RMSE for build_id_hold_out | 1.879496531954383\n",
      "####################\n",
      "RMSE for month_hold_out | 0.5699287290551007\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "print('#'*20)\n",
    "print('GroupKFold month split training...') \n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "folds = GroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "for _,df in all_readings.items():\n",
    "    df[0]['Groupkfold_by_month'] = 0\n",
    "      \n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups=split_by_month)):\n",
    "    print('Fold:',fold_+1)\n",
    "    tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]    \n",
    "    vl_x, v_y = X.iloc[val_idx,:], y[val_idx]    \n",
    "    train_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    valid_data = lgb.Dataset(vl_x, label=v_y)  \n",
    "\n",
    "    estimator = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets = [train_data, valid_data],\n",
    "            verbose_eval = 100,\n",
    "        )\n",
    "\n",
    "    for _,df in all_readings.items():\n",
    "        df[0]['Groupkfold_by_month'] += estimator.predict(df[1][features_columns])/N_SPLITS\n",
    "\n",
    "for _,df in all_readings.items():\n",
    "    print('RMSE for', df[2], '|',\n",
    "          rmse(df[0][TARGET], df[0]['Groupkfold_by_month']))\n",
    "    print('#'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings:\n",
    "\n",
    "* Dataleakage is preventing model to generalize well.\n",
    "* The best way to divide the data will be on the month basis, using 10 months for traning and 2 months for validation\n",
    "* Timesatamp has to be fixed\n",
    "* More boosting rounds with early stopping is to be used\n",
    "* Have to train several models on different SEEDS and have to average them out\n",
    "\n",
    "Train set - first 4 month\n",
    "Skip - next 4 month\n",
    "Valid set - last 4 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
